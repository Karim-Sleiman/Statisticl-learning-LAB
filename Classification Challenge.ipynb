{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import missingno as msno \n",
    "from matplotlib.pyplot import subplots\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneOut, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "from patsy import dmatrices\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from ISLP import confusion_table\n",
    "from statsmodels.stats.outliers_influence \\\n",
    "     import variance_inflation_factor as VIF\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                         summarize,\n",
    "                         poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🛠️ 1-Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = pd.read_csv('training_data/training_data.csv' , sep=\";\")\n",
    "test_data = pd.read_csv('test_data_no_target/test_data_no_target.csv', sep=\";\")\n",
    "train_data.info\n",
    "\n",
    "# Filter columns that exceed the threshold\n",
    "missing_values_count=train_data.isnull().sum()\n",
    "columns_exceeding_threshold = missing_values_count[missing_values_count > 100]\n",
    "\n",
    "\n",
    "columns_to_drop = missing_values_count[missing_values_count > 100].index\n",
    "train_data_cleaned = train_data.drop(columns=columns_to_drop)\n",
    "test_data_cleaned = test_data.drop(columns=columns_to_drop)\n",
    "train_data_cleaned.drop('Group', axis=1, inplace=True)\n",
    "test_data_cleaned.drop('Group', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "def convert_decimal_separator(df):\n",
    "    # Iterate through each column in the DataFrame\n",
    "    for column in df.columns:\n",
    "        # Replace commas with periods in the data\n",
    "        df[column] = df[column].astype(str).str.replace(',', '.')\n",
    "        \n",
    "        # Convert the column to numeric type\n",
    "        df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "\n",
    "# Call the function to convert decimal separator in X\n",
    "convert_decimal_separator(train_data_cleaned)\n",
    "\n",
    "# Call the function to convert decimal separator in X\n",
    "convert_decimal_separator(test_data_cleaned)\n",
    "\n",
    "\n",
    "#KNNImputer for train data\n",
    "\n",
    "# Display missing values by column\n",
    "missing_values_train = train_data_cleaned.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "\n",
    "# Initialize the KNNImputer with the 'nan_euclidean' metric\n",
    "knn_imputer = KNNImputer(n_neighbors=5, metric='nan_euclidean')\n",
    "\n",
    "# Fit and transform the data using KNN imputation\n",
    "# Apply KNN imputation to the numeric columns (float64 or int64)\n",
    "numeric_columns = train_data_cleaned.select_dtypes(include=['float64'])\n",
    "imputed_data = knn_imputer.fit_transform(numeric_columns)\n",
    "\n",
    "# Replace the original numeric columns in the DataFrame with the imputed data\n",
    "train_data_cleaned[numeric_columns.columns] = imputed_data\n",
    "\n",
    "# Check which columns still have missing values (this should be zero)\n",
    "missing_values_after_fill = train_data_cleaned.isnull().sum().sum()\n",
    "\n",
    "\n",
    "\n",
    "#KNNImputer for test data\n",
    "\n",
    "# Display missing values by column\n",
    "missing_values_test = test_data_cleaned.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "\n",
    "# Initialize the KNNImputer with the 'nan_euclidean' metric\n",
    "knn_imputer = KNNImputer(n_neighbors=5, metric='nan_euclidean')\n",
    "\n",
    "# Fit and transform the data using KNN imputation\n",
    "# Apply KNN imputation to the numeric columns (float64 or int64)\n",
    "numeric_columns = test_data_cleaned.select_dtypes(include=['float64'])\n",
    "imputed_data = knn_imputer.fit_transform(numeric_columns)\n",
    "\n",
    "# Replace the original numeric columns in the DataFrame with the imputed data\n",
    "test_data_cleaned[numeric_columns.columns] = imputed_data\n",
    "\n",
    "# Check which columns still have missing values (this should be zero)\n",
    "missing_values_after_fill_test = test_data_cleaned.isnull().sum().sum()\n",
    "\n",
    "\n",
    "missing_train_values_later = train_data_cleaned.isnull().sum()\n",
    "\n",
    "missing_test_values_later = test_data_cleaned.isnull().sum()\n",
    "\n",
    "# Data Preparation - Train Data without Group, Perform and Class Columns\n",
    "target= train_data_cleaned['Perform']\n",
    "classes= train_data_cleaned['Class']\n",
    "train_data_cleaned.drop(['Class','Perform'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧹 2- Feature Selection- LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names of X_train_df:\n",
      "Index(['I1', 'I2', 'I3', 'I5', 'I6', 'I7', 'I8', 'I9', 'I10', 'I11', 'I19',\n",
      "       'I20', 'I25', 'I28', 'I29', 'I30', 'I31', 'I33', 'I34', 'I35', 'I36',\n",
      "       'I37', 'I38', 'I39', 'I40', 'I41', 'I42', 'I43', 'I47', 'I53', 'I54',\n",
      "       'I56', 'dI1', 'dI2', 'dI3', 'dI5', 'dI6', 'dI7', 'dI8', 'dI9', 'dI10',\n",
      "       'dI11', 'dI19', 'dI20', 'dI25', 'dI29', 'dI30', 'dI31', 'dI33', 'dI34',\n",
      "       'dI35', 'dI36', 'dI37', 'dI39', 'dI40', 'dI41', 'dI42', 'dI47', 'dI53',\n",
      "       'dI54', 'dI56'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03346401702144419, tolerance: 0.010999377067444006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04109914030954087, tolerance: 0.010999377067444006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.042870916311485985, tolerance: 0.010999377067444006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.043231861447480924, tolerance: 0.010999377067444006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04326739160495663, tolerance: 0.010999377067444006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04323021002601024, tolerance: 0.010999377067444006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.042981724318266856, tolerance: 0.010999377067444006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04303167677809938, tolerance: 0.010999377067444006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04322589850580982, tolerance: 0.010999377067444006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04297812529809164, tolerance: 0.010999377067444006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.016280803074806727, tolerance: 0.011191484505943929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.017187807418025614, tolerance: 0.011191484505943929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.018908681480041878, tolerance: 0.011191484505943929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02011228673650578, tolerance: 0.011191484505943929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.020288095866959566, tolerance: 0.011191484505943929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0202851659189065, tolerance: 0.011191484505943929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.020251241311868284, tolerance: 0.011191484505943929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.020213256045096273, tolerance: 0.011191484505943929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.020176118693896683, tolerance: 0.011191484505943929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02014069315653444, tolerance: 0.011191484505943929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.020107095070798664, tolerance: 0.011191484505943929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.020075297681430015, tolerance: 0.011191484505943929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01593959266718059, tolerance: 0.010865481642661929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01610966120779267, tolerance: 0.010865481642661929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.016057623817232525, tolerance: 0.010865481642661929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.011366690097617038, tolerance: 0.010865481642661929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.022199307165848836, tolerance: 0.010865481642661929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02477769043058231, tolerance: 0.010865481642661929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.022809071805539816, tolerance: 0.010865481642661929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.021336790426531138, tolerance: 0.010865481642661929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.022127580433334515, tolerance: 0.010865481642661929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important features selected by Lasso: Index(['I6', 'I9', 'I28', 'I37', 'I41', 'I43', 'I47', 'dI6', 'dI9', 'dI25',\n",
      "       'dI29', 'dI47'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Store column names before splitting and scaling\n",
    "original_columns = train_data_cleaned.columns\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data_cleaned, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale your features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create DataFrames with scaled features\n",
    "X_train_df = pd.DataFrame(X_train_scaled, columns=original_columns)\n",
    "X_test_df = pd.DataFrame(X_test_scaled, columns=original_columns)\n",
    "\n",
    "# Now you can access column names from X_train_df, X_test_df, and y_train\n",
    "print(\"Column names of X_train_df:\")\n",
    "print(X_train_df.columns)\n",
    "\n",
    "# Instantiate LassoCV model\n",
    "lasso_cv = LassoCV(cv=5)  # Use 5-fold cross-validation to find the optimal alpha\n",
    "\n",
    "# Fit the model\n",
    "lasso_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Extract important features\n",
    "important_features_indices = np.where(lasso_cv.coef_ != 0)[0]\n",
    "important_features = train_data_cleaned.columns[important_features_indices]\n",
    "\n",
    "print(\"Important features selected by Lasso:\", important_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha value selected by LassoCV: 0.0028975295824779455\n"
     ]
    }
   ],
   "source": [
    "# Get the optimal alpha value\n",
    "optimal_alpha = lasso_cv.alpha_\n",
    "print(\"Optimal alpha value selected by LassoCV:\", optimal_alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names of X_train_df:\n",
      "Index(['I1', 'I2', 'I3', 'I5', 'I6', 'I7', 'I8', 'I9', 'I10', 'I11', 'I19',\n",
      "       'I20', 'I25', 'I28', 'I29', 'I30', 'I31', 'I33', 'I34', 'I35', 'I36',\n",
      "       'I37', 'I38', 'I39', 'I40', 'I41', 'I42', 'I43', 'I47', 'I53', 'I54',\n",
      "       'I56', 'dI1', 'dI2', 'dI3', 'dI5', 'dI6', 'dI7', 'dI8', 'dI9', 'dI10',\n",
      "       'dI11', 'dI19', 'dI20', 'dI25', 'dI29', 'dI30', 'dI31', 'dI33', 'dI34',\n",
      "       'dI35', 'dI36', 'dI37', 'dI39', 'dI40', 'dI41', 'dI42', 'dI47', 'dI53',\n",
      "       'dI54', 'dI56'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.031400634173877506, tolerance: 0.010999377067444006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03846217408133157, tolerance: 0.010999377067444006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.040285646576109, tolerance: 0.010999377067444006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04088096331706481, tolerance: 0.010999377067444006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.041188822493055, tolerance: 0.010999377067444006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04142214120801668, tolerance: 0.010999377067444006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0414153527163279, tolerance: 0.010999377067444006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04175658839930918, tolerance: 0.010999377067444006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04218660637461369, tolerance: 0.010999377067444006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.042123182321674335, tolerance: 0.010999377067444006\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.015063665228552736, tolerance: 0.011191484505943929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01581206721066053, tolerance: 0.011191484505943929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.017411599981883796, tolerance: 0.011191484505943929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0187057800061865, tolerance: 0.011191484505943929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.019005207770447896, tolerance: 0.011191484505943929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.019130697372375494, tolerance: 0.011191484505943929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.019220934736239315, tolerance: 0.011191484505943929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.019300727755393154, tolerance: 0.011191484505943929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01937470817836129, tolerance: 0.011191484505943929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.019443906730472804, tolerance: 0.011191484505943929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01950870861759313, tolerance: 0.011191484505943929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.019569379760270067, tolerance: 0.011191484505943929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.021272084435835836, tolerance: 0.010865481642661929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.023639690793757495, tolerance: 0.010865481642661929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.024052493273117648, tolerance: 0.010865481642661929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.021256133270838973, tolerance: 0.010865481642661929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:664: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.020771341463330373, tolerance: 0.010865481642661929\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important features selected by Elastic Net: Index(['I6', 'I9', 'I28', 'I37', 'I41', 'I43', 'I47', 'dI6', 'dI9', 'dI25',\n",
      "       'dI29', 'dI47'],\n",
      "      dtype='object')\n",
      "Optimal alpha value selected by ElasticNetCV: 0.005795059164955892\n",
      "Optimal l1_ratio value selected by ElasticNetCV: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming train_data_cleaned and target are already defined\n",
    "\n",
    "# Store column names before splitting and scaling\n",
    "original_columns = train_data_cleaned.columns\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data_cleaned, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale your features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create DataFrames with scaled features\n",
    "X_train_df = pd.DataFrame(X_train_scaled, columns=original_columns)\n",
    "X_test_df = pd.DataFrame(X_test_scaled, columns=original_columns)\n",
    "\n",
    "# Now you can access column names from X_train_df, X_test_df, and y_train\n",
    "print(\"Column names of X_train_df:\")\n",
    "print(X_train_df.columns)\n",
    "\n",
    "# Instantiate ElasticNetCV model\n",
    "elastic_net_cv = ElasticNetCV(cv=5, l1_ratio=0.5, random_state=42)  # Use 5-fold cross-validation to find the optimal alpha and l1_ratio\n",
    "\n",
    "# Fit the model\n",
    "elastic_net_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Extract important features\n",
    "important_features_indices = np.where(elastic_net_cv.coef_ != 0)[0]\n",
    "important_features = train_data_cleaned.columns[important_features_indices]\n",
    "\n",
    "print(\"Important features selected by Elastic Net:\", important_features)\n",
    "\n",
    "# Get the optimal alpha and l1_ratio values\n",
    "optimal_alpha = elastic_net_cv.alpha_\n",
    "optimal_l1_ratio = elastic_net_cv.l1_ratio_\n",
    "\n",
    "print(\"Optimal alpha value selected by ElasticNetCV:\", optimal_alpha)\n",
    "print(\"Optimal l1_ratio value selected by ElasticNetCV:\", optimal_l1_ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "elasticnet results are same with lasso, so lasso results were taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_select=['I6', 'I9', 'I28', 'I37', 'I41', 'I43', 'I47', 'dI6', 'dI9', 'dI25',\n",
    "        'dI29', 'dI47']\n",
    "\n",
    "\n",
    "# Select the columns from train_data_cleaned\n",
    "new_data = train_data_cleaned[columns_to_select]\n",
    "new_data_test = test_data_cleaned[columns_to_select]\n",
    "# Set column names for new_data\n",
    "new_data.columns = columns_to_select\n",
    "\n",
    "# Set column names for new_data_test\n",
    "new_data_test.columns = columns_to_select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📐 3- Feature Engineering – Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False)  # Change degree as needed\n",
    "new_data = poly.fit_transform(new_data)\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming `test_cleaned_data` is the cleaned test dataset and `train_data_cleaned` was the cleaned training dataset.\n",
    "\n",
    "# Step 1: Transform the test data using PolynomialFeatures (same instance used for training data)\n",
    "X_test_interactions = poly.transform(new_data_test)\n",
    "\n",
    "# Step 2: Convert the interaction features to a DataFrame using the column names from the training data\n",
    "new_data_test = pd.DataFrame(X_test_interactions, columns=poly.get_feature_names_out(new_data_test.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🌲 4- Classification - Random Forest Model with Bagging (Bootstrap Aggregating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Random Forest Accuracy: 0.46125\n",
      "Bagging Random Forest Accuracy: 0.466875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Assuming new_data and classes are your data and target labels\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_data, classes, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize base Random Forest classifier\n",
    "base_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Initialize Bagging classifier with Random Forest as base estimator\n",
    "bagging_rf = BaggingClassifier(base_rf, n_estimators=10, random_state=42)\n",
    "\n",
    "# Train base Random Forest classifier\n",
    "base_rf.fit(X_train, y_train)\n",
    "\n",
    "# Train Bagging classifier\n",
    "bagging_rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate base Random Forest classifier\n",
    "base_rf_score = base_rf.score(X_test, y_test)\n",
    "print(\"Base Random Forest Accuracy:\", base_rf_score)\n",
    "\n",
    "# Evaluate Bagging classifier\n",
    "bagging_rf_score = bagging_rf.score(X_test, y_test)\n",
    "print(\"Bagging Random Forest Accuracy:\", bagging_rf_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\beyza\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but BaggingClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Random Forest predictions: [ 1  1 -1 ...  1  1  1]\n",
      "Bagging Random Forest predictions: [ 1  1 -1 ...  1  1 -1]\n"
     ]
    }
   ],
   "source": [
    "# Assuming new_data_test is a NumPy array containing your new test data\n",
    "\n",
    "# Make predictions on new test data using the base Random Forest classifier\n",
    "base_rf_predictions = base_rf.predict(new_data_test)\n",
    "\n",
    "# Make predictions on new test data using the Bagging classifier\n",
    "bagging_rf_predictions = bagging_rf.predict(new_data_test)\n",
    "\n",
    "# Print predictions\n",
    "print(\"Base Random Forest predictions:\", base_rf_predictions)\n",
    "print(\"Bagging Random Forest predictions:\", bagging_rf_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 💾 5- Save Predicitons to CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions_test_model = bagging_rf_predictions.flatten()\n",
    "\n",
    "\n",
    "# Creating a DataFrame with predictions and the second column\n",
    "data = {\n",
    "        'Predictions_Decisiontree': predictions_test_model}\n",
    "\n",
    "# Create DataFrame\n",
    "predictions_df = pd.DataFrame(data)\n",
    "\n",
    "# Export predictions to a CSV file without a header\n",
    "predictions_df.to_csv('Result.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
